# ðŸ¤– AI/ML Architecture & Integration Guide

## ðŸ“‹ **Table of Contents**

- [Overview](#overview)
- [Architecture](#architecture)
- [AI Models Directory Structure](#ai-models-directory-structure)
- [Model Categories](#model-categories)
- [Integration Points](#integration-points)
- [How to Use AI Models](#how-to-use-ai-models)
- [Advanced Features](#advanced-features)
- [Performance & Scaling](#performance--scaling)
- [Troubleshooting](#troubleshooting)

---

## ðŸŽ¯ **Overview**

Social Flow Backend integrates **20+ advanced AI/ML models** across 5 major categories to provide intelligent, personalized, and safe content experiences. The AI system is modular, scalable, and production-ready.

### **Key Capabilities**

- ðŸ›¡ï¸ **Content Moderation**: NSFW, spam, toxicity, violence detection
- ðŸŽ¯ **Recommendations**: 8 different algorithms (collaborative, content-based, transformers, GNN)
- ðŸŽ¥ **Video Analysis**: Scene detection, object tracking, action recognition
- ðŸ’­ **Sentiment Analysis**: Emotion detection, intent recognition
- ðŸ“ˆ **Trend Prediction**: Viral potential, engagement forecasting

### **Technology Stack**

- **Deep Learning**: PyTorch, Transformers (BERT, CLIP)
- **Computer Vision**: OpenCV, TorchVision (ResNet, YOLO)
- **NLP**: Transformers, Detoxify, Sentiment Analysis
- **ML Frameworks**: Scikit-learn, NumPy, Pandas
- **Orchestration**: Custom pipeline orchestrator with task scheduling

---

## ðŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  FastAPI Endpoints (app/api/v1/endpoints/)                 â”‚â”‚
â”‚  â”‚  - ai_pipelines.py (15 endpoints)                          â”‚â”‚
â”‚  â”‚  - videos.py, social.py, search.py (AI-enhanced)           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                   â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ML Service Layer (app/ml/)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  MLService (ml/services/ml_service.py)                     â”‚â”‚
â”‚  â”‚  - Unified interface for all AI operations                 â”‚â”‚
â”‚  â”‚  - Model loading and caching                               â”‚â”‚
â”‚  â”‚  - Error handling and fallbacks                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Models   â”‚ â”‚ ML Pipelines â”‚ â”‚  Recommendation  â”‚
â”‚  (ai_models/)â”‚ â”‚(ml_pipelines/)â”‚ â”‚    Service       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Celery Workers (Background)  â”‚
        â”‚  - Video analysis             â”‚
        â”‚  - Recommendation computation â”‚
        â”‚  - Batch processing           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow**

```
User Request â†’ FastAPI Endpoint â†’ ML Service â†’ AI Model â†’ Response
                                       â†“
                                  Cache (Redis)
                                       â†“
                              Background Tasks (Celery)
                                       â†“
                              Pipeline Orchestrator
```

---

## ðŸ“ **AI Models Directory Structure**

```
app/ai_models/
â”œâ”€â”€ __init__.py                      # Main package exports
â”œâ”€â”€ content_moderation/              # Safety & moderation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ detectors.py                # 4 detector classes
â”‚       â”œâ”€â”€ NSFWDetector            # NSFW content detection
â”‚       â”œâ”€â”€ SpamDetector            # Spam & bot detection
â”‚       â”œâ”€â”€ ViolenceDetector        # Violence detection
â”‚       â””â”€â”€ ToxicityDetector        # Hate speech detection
â”‚
â”œâ”€â”€ recommendation/                  # Recommendation engines
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ recommenders.py             # 4 basic recommenders
â”‚   â”‚   â”œâ”€â”€ ContentBasedRecommender
â”‚   â”‚   â”œâ”€â”€ CollaborativeFilteringRecommender
â”‚   â”‚   â”œâ”€â”€ DeepLearningRecommender
â”‚   â”‚   â””â”€â”€ TrendingRecommender
â”‚   â””â”€â”€ advanced_recommenders.py    # 4 advanced recommenders
â”‚       â”œâ”€â”€ TransformerRecommender  # BERT-based
â”‚       â”œâ”€â”€ NeuralCFRecommender     # Neural collaborative
â”‚       â”œâ”€â”€ GraphRecommender        # GNN-based
â”‚       â””â”€â”€ MultiArmedBandit        # Smart selection
â”‚
â”œâ”€â”€ video_analysis/                  # Video processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzers.py                # 5 analysis classes
â”‚   â”‚   â”œâ”€â”€ SceneDetector           # Scene segmentation
â”‚   â”‚   â”œâ”€â”€ ObjectDetector          # Object detection/tracking
â”‚   â”‚   â”œâ”€â”€ ActionRecognizer        # Action recognition
â”‚   â”‚   â”œâ”€â”€ VideoQualityAnalyzer    # Quality assessment
â”‚   â”‚   â””â”€â”€ ThumbnailGenerator      # Smart thumbnail generation
â”‚   â””â”€â”€ advanced_analyzers.py       # Advanced video AI
â”‚       â”œâ”€â”€ DeepVideoAnalyzer       # Multi-modal analysis
â”‚       â”œâ”€â”€ ContentFingerprintGenerator
â”‚       â””â”€â”€ VideoSearchIndexer
â”‚
â”œâ”€â”€ sentiment_analysis/              # NLP & sentiment
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ analyzers.py                # 3 analyzer classes
â”‚       â”œâ”€â”€ SentimentAnalyzer       # Positive/negative/neutral
â”‚       â”œâ”€â”€ EmotionDetector         # 7 emotions
â”‚       â””â”€â”€ IntentRecognizer        # User intent
â”‚
â””â”€â”€ trending_prediction/             # Trend forecasting
    â”œâ”€â”€ __init__.py
    â””â”€â”€ predictors.py               # 3 predictor classes
        â”œâ”€â”€ TrendPredictor          # Trend identification
        â”œâ”€â”€ TrendAnalyzer           # Trend analysis
        â””â”€â”€ EngagementForecaster    # Engagement prediction
```

### **Total AI Models: 23 Classes**

- **Content Moderation**: 4 models
- **Recommendations**: 8 models (4 basic + 4 advanced)
- **Video Analysis**: 8 models (5 basic + 3 advanced)
- **Sentiment Analysis**: 3 models
- **Trend Prediction**: 3 models

---

## ðŸŽ¯ **Model Categories**

### **1. Content Moderation (4 Models)**

#### **NSFWDetector**
- **Purpose**: Detect NSFW/adult content in images and videos
- **Technology**: CLIP (OpenAI) + ResNet50
- **Features**:
  - Multi-category classification (safe, suggestive, explicit, racy, violence, gore)
  - Regional analysis for localized NSFW content
  - Ensemble prediction with confidence scores
  - GPU acceleration support

```python
from app.ai_models.content_moderation import NSFWDetector

detector = NSFWDetector()
result = await detector.detect(image_url)
# Returns: {
#   "is_nsfw": False,
#   "confidence": 0.95,
#   "categories": {"safe": 0.95, "explicit": 0.01, ...},
#   "recommended_action": "approve"
# }
```

#### **SpamDetector**
- **Purpose**: Detect spam, bots, and low-quality content
- **Technology**: BERT + behavioral analysis
- **Features**:
  - Text pattern recognition
  - URL and link analysis
  - User behavior scoring
  - Multi-language support

#### **ViolenceDetector**
- **Purpose**: Detect violent or graphic content
- **Technology**: Computer vision + temporal analysis
- **Features**:
  - Scene-by-scene violence scoring
  - Blood/gore detection
  - Weapon detection
  - Context-aware analysis

#### **ToxicityDetector**
- **Purpose**: Detect hate speech, toxic language, harassment
- **Technology**: Detoxify (Unitary) + custom models
- **Features**:
  - Multi-label classification (toxicity, severe toxicity, obscene, threat, insult, identity hate)
  - Context understanding
  - Sarcasm detection
  - Cultural sensitivity

---

### **2. Recommendation Engines (8 Models)**

#### **Basic Recommenders (4)**

##### **ContentBasedRecommender**
- **Algorithm**: Deep learning embeddings
- **Features**: Title, description, tags, category similarity
- **Best For**: New users, cold start problem
- **Embedding Dimension**: 512

##### **CollaborativeFilteringRecommender**
- **Algorithm**: Matrix factorization (SVD++)
- **Features**: User-item interactions, ratings
- **Best For**: Users with interaction history
- **Factors**: 100

##### **DeepLearningRecommender**
- **Algorithm**: Neural network (transformer-based)
- **Features**: Multi-signal deep learning
- **Best For**: Complex patterns, context-aware
- **Architecture**: 3-layer transformer

##### **TrendingRecommender**
- **Algorithm**: Engagement-based ranking
- **Features**: Views, likes, shares, velocity
- **Best For**: Discovery, viral content
- **Time Window**: Rolling 24-48 hours

#### **Advanced Recommenders (4)**

##### **TransformerRecommender**
- **Technology**: BERT-based semantic matching
- **Features**:
  - Semantic understanding of content
  - Context-aware recommendations
  - Sequential user behavior modeling
  - Attention mechanism for feature importance

##### **NeuralCFRecommender**
- **Technology**: Neural collaborative filtering (NCF)
- **Features**:
  - Non-linear user-item interactions
  - Deep feature learning
  - Implicit feedback modeling
  - Hybrid architecture (GMF + MLP)

##### **GraphRecommender**
- **Technology**: Graph Neural Networks (GNN)
- **Features**:
  - Social network analysis
  - Multi-hop neighborhood aggregation
  - Influence propagation
  - Community detection

##### **MultiArmedBandit**
- **Technology**: Reinforcement learning (Thompson Sampling)
- **Features**:
  - Auto-selects best algorithm per user
  - Exploration vs exploitation balance
  - Real-time performance tracking
  - Adaptive learning

---

### **3. Video Analysis (8 Models)**

#### **SceneDetector**
- **Purpose**: Segment videos into meaningful scenes
- **Features**:
  - Shot boundary detection
  - Scene classification (action, dialogue, transition)
  - Keyframe extraction
  - Temporal segmentation

#### **ObjectDetector**
- **Purpose**: Detect and track objects in videos
- **Technology**: YOLO v8 / Faster R-CNN
- **Features**:
  - Real-time object detection
  - Multi-object tracking
  - 80+ object classes
  - Bounding box coordinates

#### **ActionRecognizer**
- **Purpose**: Recognize human actions and activities
- **Technology**: 3D CNN (I3D/SlowFast)
- **Features**:
  - 400+ action classes
  - Temporal action localization
  - Multi-person tracking
  - Sports action recognition

#### **VideoQualityAnalyzer**
- **Purpose**: Assess video technical quality
- **Features**:
  - Resolution analysis
  - Bitrate optimization
  - Frame rate detection
  - Audio quality assessment
  - Compression artifact detection

#### **ThumbnailGenerator**
- **Purpose**: Generate optimal video thumbnails
- **Features**:
  - Saliency detection
  - Face detection
  - Visual appeal scoring
  - A/B testing support

#### **DeepVideoAnalyzer** (Advanced)
- **Purpose**: Multi-modal video understanding
- **Technology**: Multi-modal transformers
- **Features**:
  - Visual + audio + text analysis
  - Action-object relationships
  - Temporal reasoning
  - Video captioning

#### **ContentFingerprintGenerator** (Advanced)
- **Purpose**: Create unique video fingerprints
- **Features**:
  - Copyright detection
  - Duplicate video detection
  - Perceptual hashing
  - Similarity search

#### **VideoSearchIndexer** (Advanced)
- **Purpose**: Enable semantic video search
- **Features**:
  - Frame-level embedding
  - Natural language queries
  - Temporal search
  - Cross-modal retrieval

---

### **4. Sentiment Analysis (3 Models)**

#### **SentimentAnalyzer**
- **Purpose**: Analyze text sentiment
- **Output**: Positive, Negative, Neutral (with confidence)
- **Features**:
  - Multi-language support
  - Context awareness
  - Emoji interpretation
  - Sarcasm detection

#### **EmotionDetector**
- **Purpose**: Detect fine-grained emotions
- **Emotions**: Joy, Sadness, Anger, Fear, Surprise, Disgust, Neutral
- **Features**:
  - Multi-label emotion classification
  - Intensity scoring
  - Emotion transitions
  - Cultural context

#### **IntentRecognizer**
- **Purpose**: Understand user intent
- **Intents**: Question, Statement, Command, Complaint, Praise, Request
- **Features**:
  - Conversational AI
  - Action prediction
  - Context tracking
  - Multi-turn dialogue

---

### **5. Trend Prediction (3 Models)**

#### **TrendPredictor**
- **Purpose**: Identify emerging trends
- **Features**:
  - Hashtag trend detection
  - Topic clustering
  - Velocity analysis
  - Time series forecasting

#### **TrendAnalyzer**
- **Purpose**: Analyze trend characteristics
- **Features**:
  - Trend lifecycle stages
  - Peak prediction
  - Decay analysis
  - Geographic spread

#### **EngagementForecaster**
- **Purpose**: Predict content engagement
- **Metrics**: Views, likes, shares, comments
- **Features**:
  - Time series prediction
  - Viral coefficient estimation
  - Audience growth forecasting
  - ROI prediction

---

## ðŸ”— **Integration Points**

### **1. ML Service (app/ml/services/ml_service.py)**

The **MLService** class is the central hub for all AI operations:

```python
from app.ml.services.ml_service import ml_service

# Video Analysis
analysis = await ml_service.analyze_video(video_url)

# Content Moderation
moderation = await ml_service.moderate_content("text", content_data)

# Recommendations
recommendations = await ml_service.generate_recommendations(user_id, "video", 10)

# Sentiment Analysis
sentiment = await ml_service.analyze_sentiment(text)

# Trend Prediction
viral_score = await ml_service.predict_viral_potential(content_data)
```

### **2. Recommendation Service (app/services/recommendation_service.py)**

Enhanced recommendation service with ML integration:

```python
from app.services.recommendation_service import RecommendationService

service = RecommendationService(db)

# Get recommendations with specific algorithm
videos = await service.get_video_recommendations(
    user_id=user_id,
    limit=20,
    algorithm="transformer"  # or "neural_cf", "graph", "smart"
)
```

**Available Algorithms**:
- `hybrid`: Combined traditional approach (default)
- `trending`: Popular videos
- `collaborative`: Similar users
- `content_based`: Similar content
- `transformer`: BERT-based semantic matching âœ¨
- `neural_cf`: Neural collaborative filtering âœ¨
- `graph`: Social network-aware âœ¨
- `smart`: Auto-select best with bandit âœ¨

### **3. API Endpoints (app/api/v1/endpoints/ai_pipelines.py)**

15 dedicated AI/ML endpoints:

```http
# Recommendations
POST /api/v1/ai-pipelines/recommendations
POST /api/v1/ai-pipelines/recommendations/batch

# Pipeline Management
POST /api/v1/ai-pipelines/pipelines/batch-video-analysis
POST /api/v1/ai-pipelines/pipelines/recommendation-precompute
POST /api/v1/ai-pipelines/pipelines/cache-warm
GET  /api/v1/ai-pipelines/pipelines/{task_id}
POST /api/v1/ai-pipelines/pipelines/{task_id}/cancel

# Orchestration
GET  /api/v1/ai-pipelines/orchestrator/status
GET  /api/v1/ai-pipelines/orchestrator/tasks
POST /api/v1/ai-pipelines/orchestrator/shutdown

# Scheduling
POST /api/v1/ai-pipelines/scheduler/schedule
GET  /api/v1/ai-pipelines/scheduler/jobs
POST /api/v1/ai-pipelines/scheduler/jobs/{job_id}/pause
POST /api/v1/ai-pipelines/scheduler/jobs/{job_id}/resume
DELETE /api/v1/ai-pipelines/scheduler/jobs/{job_id}
```

### **4. ML Pipelines (app/ml_pipelines/)**

#### **Pipeline Orchestrator**
- Coordinates all AI pipeline tasks
- Priority-based task queue
- Concurrent execution with resource limits
- Progress tracking and monitoring

#### **Batch Processor**
- Bulk video analysis
- Batch recommendation computation
- Distributed processing

#### **Recommendation Precomputer**
- Pre-compute recommendations for active users
- Cache warming
- Scheduled updates

#### **Scheduler**
- Cron-like job scheduling
- 3 automated tasks:
  - Cache warming (every 30 min)
  - Recommendation precompute (every 2 hours)
  - Trending content update (every hour)

---

## ðŸ“– **How to Use AI Models**

### **Example 1: Content Moderation on Upload**

```python
from app.ai_models.content_moderation import NSFWDetector, ToxicityDetector

# Initialize detectors
nsfw_detector = NSFWDetector()
toxicity_detector = ToxicityDetector()

# Check video thumbnail
nsfw_result = await nsfw_detector.detect(thumbnail_url)
if nsfw_result["is_nsfw"] and nsfw_result["confidence"] > 0.85:
    # Flag for review or reject
    video.moderation_status = ModerationStatus.FLAGGED
    
# Check video description
toxicity_result = await toxicity_detector.detect(description)
if toxicity_result["is_toxic"] and toxicity_result["confidence"] > 0.90:
    # Flag for review
    video.moderation_status = ModerationStatus.FLAGGED
```

### **Example 2: Personalized Recommendations**

```python
from app.services.recommendation_service import RecommendationService

service = RecommendationService(db)

# Get smart recommendations (auto-selects best algorithm)
recommendations = await service.get_video_recommendations(
    user_id=current_user.id,
    limit=20,
    algorithm="smart"
)

# Get transformer-based recommendations
semantic_recs = await service.get_video_recommendations(
    user_id=current_user.id,
    limit=10,
    algorithm="transformer"
)
```

### **Example 3: Video Analysis Pipeline**

```python
from app.ml_pipelines.orchestrator import PipelineOrchestrator, PipelineType

orchestrator = PipelineOrchestrator()
await orchestrator.initialize()

# Submit batch video analysis
task = await orchestrator.submit_task(
    pipeline_type=PipelineType.BATCH_VIDEO_ANALYSIS,
    name="Analyze new uploads",
    config={
        "video_ids": [video1.id, video2.id, video3.id],
        "analyses": ["scene", "object", "action", "quality"]
    },
    priority=7
)

# Check progress
status = await orchestrator.get_task_status(task.task_id)
print(f"Progress: {status['progress']}%")
```

### **Example 4: Sentiment Analysis on Comments**

```python
from app.ai_models.sentiment_analysis import SentimentAnalyzer, EmotionDetector

sentiment_analyzer = SentimentAnalyzer()
emotion_detector = EmotionDetector()

# Analyze comment sentiment
sentiment = await sentiment_analyzer.analyze(comment.text)
comment.sentiment = sentiment["sentiment"]  # positive/negative/neutral
comment.sentiment_score = sentiment["confidence"]

# Detect emotions
emotions = await emotion_detector.detect(comment.text)
dominant_emotion = max(emotions["emotions"].items(), key=lambda x: x[1])
comment.emotion = dominant_emotion[0]
```

### **Example 5: Viral Potential Prediction**

```python
from app.ai_models.trending_prediction import EngagementForecaster
from app.ml.services.ml_service import ml_service

# Predict viral potential
viral_prediction = await ml_service.predict_viral_potential({
    "video_id": video.id,
    "title": video.title,
    "description": video.description,
    "tags": video.tags,
    "creator_followers": creator.follower_count,
    "initial_engagement": {
        "views": video.view_count,
        "likes": video.like_count,
        "comments": video.comment_count
    }
})

if viral_prediction["viral_score"] > 0.85:
    # Boost in recommendations
    video.is_promoted = True
    video.viral_score = viral_prediction["viral_score"]
```

---

## ðŸš€ **Advanced Features**

### **1. Model Ensemble**

Combine multiple models for better accuracy:

```python
# Content moderation ensemble
async def moderate_content_ensemble(content):
    nsfw_result = await nsfw_detector.detect(content)
    violence_result = await violence_detector.detect(content)
    toxicity_result = await toxicity_detector.detect(content)
    
    # Weighted average
    risk_score = (
        nsfw_result["confidence"] * 0.4 +
        violence_result["confidence"] * 0.4 +
        toxicity_result["confidence"] * 0.2
    )
    
    return risk_score > 0.75  # Flag if high risk
```

### **2. Hybrid Recommendations**

Mix multiple recommendation algorithms:

```python
# 20% Transformer + 20% Neural CF + 20% Graph + 40% Traditional
hybrid_recs = []
hybrid_recs.extend(await get_transformer_recs(user_id, 4))
hybrid_recs.extend(await get_neural_cf_recs(user_id, 4))
hybrid_recs.extend(await get_graph_recs(user_id, 4))
hybrid_recs.extend(await get_collaborative_recs(user_id, 8))

# Deduplicate and rank
final_recs = rank_and_diversify(hybrid_recs, limit=20)
```

### **3. Real-Time Adaptation**

Multi-armed bandit for adaptive recommendations:

```python
from app.ai_models.recommendation import MultiArmedBandit

bandit = MultiArmedBandit()

# Auto-select best algorithm per user
algorithm = await bandit.select_algorithm(user_id)
recommendations = await service.get_video_recommendations(
    user_id=user_id,
    algorithm=algorithm
)

# Update performance
await bandit.update_reward(user_id, algorithm, engagement_score)
```

### **4. Scheduled Tasks**

Automated background AI processing:

```python
# In app/ml_pipelines/scheduler.py
scheduler.add_job(
    func=warm_cache,
    trigger="interval",
    minutes=30,
    id="cache_warmer"
)

scheduler.add_job(
    func=precompute_recommendations,
    trigger="interval",
    hours=2,
    id="recommendation_precomputer"
)

scheduler.add_job(
    func=update_trending,
    trigger="interval",
    hours=1,
    id="trending_updater"
)
```

---

## âš¡ **Performance & Scaling**

### **Optimization Strategies**

1. **Model Caching**
   - Load models once on startup
   - Keep in memory for fast inference
   - Use Redis for result caching

2. **Batch Processing**
   - Process multiple videos at once
   - Reduce model loading overhead
   - GPU batch inference

3. **Async Execution**
   - Non-blocking model inference
   - Concurrent processing
   - Background task queues (Celery)

4. **Lazy Loading**
   - Load models on first use
   - Optional dependencies (torch, transformers)
   - Graceful degradation

5. **Result Caching**
   ```python
   # Cache recommendations for 15 minutes
   cache_key = f"recs:{user_id}:{algorithm}"
   await redis.setex(cache_key, 900, json.dumps(recommendations))
   ```

### **Resource Requirements**

| Model Type | CPU | RAM | GPU | Load Time |
|-----------|-----|-----|-----|-----------|
| NSFW Detector | 2 cores | 2 GB | Optional | 5-10s |
| Spam Detector | 1 core | 512 MB | No | 1-2s |
| Content-Based Rec | 1 core | 1 GB | No | 2-3s |
| Transformer Rec | 4 cores | 4 GB | Recommended | 10-15s |
| Video Analysis | 4 cores | 4 GB | Recommended | 15-20s |

**Production Recommendations**:
- **Min**: 8 cores, 16 GB RAM, no GPU (basic features)
- **Recommended**: 16 cores, 32 GB RAM, NVIDIA T4/V100 (all features)
- **Optimal**: 32 cores, 64 GB RAM, NVIDIA A100 (high load)

---

## ðŸ”§ **Troubleshooting**

### **Models Not Loading**

```python
# Check if AI libraries are installed
pip install torch transformers opencv-python detoxify

# Verify installation
python -c "import torch; print(torch.__version__)"
python -c "import transformers; print(transformers.__version__)"
```

### **GPU Not Detected**

```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU count: {torch.cuda.device_count()}")

# Force CPU mode
device = torch.device("cpu")
```

### **Out of Memory**

```python
# Reduce batch size
config = {
    "batch_size": 8,  # Try 4 or 2
    "max_concurrent_tasks": 2  # Reduce parallel tasks
}

# Use CPU instead of GPU
os.environ["CUDA_VISIBLE_DEVICES"] = ""
```

### **Slow Inference**

```python
# Enable model caching
from functools import lru_cache

@lru_cache(maxsize=1)
def load_model():
    return NSFWDetector()

# Use smaller models
config = {
    "model_size": "small",  # instead of "large"
    "use_quantization": True
}
```

---

## ðŸ“Š **Monitoring & Metrics**

### **Key Metrics**

```python
# Model performance
- Inference time (ms)
- Throughput (requests/sec)
- Accuracy/Precision/Recall
- GPU utilization

# Business metrics
- Recommendation CTR
- Moderation accuracy
- User engagement lift
- Viral prediction accuracy
```

### **Logging**

```python
logger.info(f"NSFW detection: {confidence:.2f} confidence in {elapsed:.2f}ms")
logger.warning(f"Model inference slow: {elapsed}ms > {threshold}ms")
logger.error(f"Model loading failed: {error}")
```

---

## ðŸŽ“ **Next Steps**

1. **For Developers**: Review the code in `app/ai_models/` to understand implementations
2. **For ML Engineers**: Check `app/ml_pipelines/` for pipeline architecture
3. **For API Users**: Test the AI endpoints at `/docs` (Swagger UI)
4. **For DevOps**: Review deployment requirements and scaling strategies

---

## ðŸ“š **Additional Resources**

- **[AI Quick Start Guide](AI_QUICK_START.md)** - Get started with AI features
- **[ML Service Integration](PHASE_3_ML_SERVICE_INTEGRATION_COMPLETE.md)** - Integration details
- **[API Documentation](API_DOCUMENTATION.md)** - Complete API reference
- **[Video Analysis Guide](docs/video_analysis.md)** - Video processing details

---

<div align="center">

**ðŸ¤– Powered by Advanced AI/ML**

Built with PyTorch â€¢ Transformers â€¢ OpenCV â€¢ Scikit-learn

</div>
